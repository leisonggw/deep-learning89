{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42YY2efMTZce"
      },
      "source": [
        "# **Homework 1 Deep learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRdtNDF4SQGx"
      },
      "source": [
        "This file is for the homework of 6289 deep learning. In this file, we implement the Pytorch tutorial and try some code on our own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-b7mfRsTvaH"
      },
      "source": [
        "# Basic Python\n",
        "Since I am still quite new to Python, we will start from some basic concepts such as tuple, list, loop etc. Here we can see list is changalbe while tuple is not. Then some examples of function and logic operation are showed. Fibonacci function would be a nice example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoiJKSzrUQ9c",
        "outputId": "584d5729-70c3-4871-88d3-61ca422df2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "a=[1,2,3]\n",
        "b=(1,2,3)\n",
        "a[1]=1\n",
        "a\n",
        "\n",
        "def Fibonacci(n):\n",
        "    if n<=0:\n",
        "        print(\"Positive Integer Plz\")\n",
        "    elif n==1:\n",
        "        return 0\n",
        "    elif n==2:\n",
        "        return 1\n",
        "    else:\n",
        "        return Fibonacci(n-1)+Fibonacci(n-2)\n",
        " \n",
        "print(Fibonacci(10))\n",
        "\n",
        "!pip install matplotlib"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12FFScF1TgC"
      },
      "source": [
        "# PyTorch and Matrix\n",
        "\n",
        "Import the torch first, then we can creat tensors from  Python lists. torch.dim and torch.shape could give the rank and dimension of the tensors. You can also force a datatype for a tensor using parameter dtype. \n",
        "\n",
        "Here are some some useful function to generate special matrixs, eye for identity matrix, zeors for zero matrix, ones for 1 matrixs, rand for random matrixs.\n",
        "\n",
        "Indexes here could be used to select certain row, column or subpart of the matrix. We can also creat an empty tensor. The indexing here is inexclusive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZtWWWfx1T2i",
        "outputId": "35a0dcde-b449-402c-d0e4-f123129011ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "\n",
        "a = torch.tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "print(a)\n",
        "print('type(a): ', type(a))\n",
        "print('rank of a: ', a.dim())\n",
        "print('a.shape: ', a.shape)\n",
        "\n",
        "emptym = torch.tensor([])\n",
        "zerom = torch.zeros(3, 3)\n",
        "onem = torch.ones(3, 3)\n",
        "idenm = torch.eye(3)\n",
        "randm = torch.rand(3, 3)\n",
        "print(emptym)\n",
        "print(zerom)\n",
        "print(onem)\n",
        "print(idenm)\n",
        "print(randm)\n",
        "\n",
        "print('Original tensor:')\n",
        "print(a)\n",
        "print('shape: ', a.shape)\n",
        "\n",
        "# Get row 1, and all columns. \n",
        "print('\\nSingle row:')\n",
        "print(a[1, :])\n",
        "print(a[1])  # Gives the same result; we can omit : for trailing dimensions\n",
        "print('shape: ', a[1].shape)\n",
        "\n",
        "print('\\nSingle column:')\n",
        "print(a[:, 1])\n",
        "print('shape: ', a[:, 1].shape)\n",
        "\n",
        "# Get the first two rows and the last three columns\n",
        "print('\\nFirst two rows, last two columns:')\n",
        "print(a[:2, -3:])\n",
        "print('shape: ', a[:2, -3:].shape)\n",
        "\n",
        "# Get every other row, and columns at index 1 and 2\n",
        "print('\\nEvery other row, middle columns:')\n",
        "print(a[::2, 1:3])\n",
        "print('shape: ', a[::2, 1:3].shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0+cu101\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "type(a):  <class 'torch.Tensor'>\n",
            "rank of a:  2\n",
            "a.shape:  torch.Size([3, 4])\n",
            "tensor([])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "tensor([[0.6329, 0.6266, 0.6940],\n",
            "        [0.0869, 0.3755, 0.4374],\n",
            "        [0.7401, 0.6807, 0.6011]])\n",
            "Original tensor:\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "shape:  torch.Size([3, 4])\n",
            "\n",
            "Single row:\n",
            "tensor([5, 6, 7, 8])\n",
            "tensor([5, 6, 7, 8])\n",
            "shape:  torch.Size([4])\n",
            "\n",
            "Single column:\n",
            "tensor([ 2,  6, 10])\n",
            "shape:  torch.Size([3])\n",
            "\n",
            "First two rows, last two columns:\n",
            "tensor([[2, 3, 4],\n",
            "        [6, 7, 8]])\n",
            "shape:  torch.Size([2, 3])\n",
            "\n",
            "Every other row, middle columns:\n",
            "tensor([[ 2,  3],\n",
            "        [10, 11]])\n",
            "shape:  torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miJl5kKWSOQI"
      },
      "source": [
        "One thing that should be noted is the .clone(). Assigning value to certain part of a tensor is assigning to the original tensor. So .clone() is useful in creating a new tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jbah0sD1qRg"
      },
      "source": [
        "a = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "b = a[0, 1:]\n",
        "c = a[0, 1:].clone()\n",
        "print('Before mutating:')\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "\n",
        "a[0, 1] = 20  # a[0, 1] and b[0] point to the same element\n",
        "b[1] = 30     # b[1] and a[0, 2] point to the same element\n",
        "c[2] = 40     # c is a clone, so it has its own data\n",
        "print('\\nAfter mutating:')\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RCHxVF-y-7t"
      },
      "source": [
        "Then we focus on the matrix calculation. First is the elementwise calculation. For 2 tensors, the normal calculation is all elementwise. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHITOMGWy_0V"
      },
      "source": [
        "x = torch.tensor([[1, 2, 3, 4]])\n",
        "y = torch.tensor([[5, 6, 7, 8]])\n",
        "\n",
        "print('Elementwise sum:')\n",
        "print(x + y)\n",
        "print(torch.add(x, y))\n",
        "print(x.add(y))\n",
        "\n",
        "# Elementwise difference\n",
        "print('\\nElementwise difference:')\n",
        "print(x - y)\n",
        "print(torch.sub(x, y))\n",
        "print(x.sub(y))\n",
        "\n",
        "# Elementwise product\n",
        "print('\\nElementwise product:')\n",
        "print(x * y)\n",
        "print(torch.mul(x, y))\n",
        "print(x.mul(y))\n",
        "\n",
        "# Elementwise division\n",
        "print('\\nElementwise division')\n",
        "print(x / y)\n",
        "print(torch.div(x, y))\n",
        "print(x.div(y))\n",
        "\n",
        "# Elementwise power\n",
        "print('\\nElementwise power')\n",
        "print(x ** y)\n",
        "print(torch.pow(x, y))\n",
        "print(x.pow(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KjV6p2y1xLw"
      },
      "source": [
        "Here some basic matrix operations are showed, such as transopse, matrix product, inverse etc. Floor function is also given. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGC0r_g_2cR9",
        "outputId": "44caf151-8951-493e-dd55-65ca2438a2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "x = torch.rand((3,3))\n",
        "\n",
        "print(x), x.shape\n",
        "#scale first \n",
        "\n",
        "\n",
        "print(2*x)\n",
        "print(2+x)\n",
        "print(torch.ceil(x))\n",
        "print(torch.t(x))\n",
        "\n",
        "y=torch.eye(3)\n",
        "z=torch.zeros(3,3)\n",
        "\n",
        "print(torch.mm(x,z))\n",
        "print(x@y)\n",
        "\n",
        "t=torch.inverse(x)\n",
        "print(t)\n",
        "print(t@x)\n",
        "#M+mat1/*/mat2\n",
        "M = torch.randn(2, 3)\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "torch.addmm(M, mat1, mat2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0247, 0.3489, 0.8341],\n",
            "        [0.0135, 0.5318, 0.3790],\n",
            "        [0.0652, 0.0941, 0.0437]])\n",
            "tensor([[0.0495, 0.6978, 1.6681],\n",
            "        [0.0271, 1.0635, 0.7580],\n",
            "        [0.1304, 0.1881, 0.0873]])\n",
            "tensor([[2.0247, 2.3489, 2.8341],\n",
            "        [2.0135, 2.5318, 2.3790],\n",
            "        [2.0652, 2.0941, 2.0437]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0.0247, 0.0135, 0.0652],\n",
            "        [0.3489, 0.5318, 0.0941],\n",
            "        [0.8341, 0.3790, 0.0437]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[0.0247, 0.3489, 0.8341],\n",
            "        [0.0135, 0.5318, 0.3790],\n",
            "        [0.0652, 0.0941, 0.0437]])\n",
            "tensor([[ 0.6292, -3.2003, 15.7605],\n",
            "        [-1.2212,  2.6989, -0.0969],\n",
            "        [ 1.6912, -1.0340, -0.4271]])\n",
            "tensor([[ 1.0000e+00, -1.5333e-07,  2.0123e-09],\n",
            "        [ 4.5493e-09,  1.0000e+00, -1.1170e-07],\n",
            "        [-2.4510e-09, -2.8327e-08,  1.0000e+00]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3153, -1.1431, -1.3456],\n",
              "        [ 0.4520,  0.6048,  2.8871]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjCLupDj7eNG"
      },
      "source": [
        "Outer product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc9zDmm76GNA",
        "outputId": "05ce0d47-f65b-4209-a292-f7d985f265c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "v1 = torch.arange(1, 4)    # Size 3\n",
        "v2 = torch.arange(1, 3)    # Size 2\n",
        "r = torch.ger(v1, v2)\n",
        "print(v1)\n",
        "print(v2)\n",
        "print(r)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([1, 2])\n",
            "tensor([[1, 2],\n",
            "        [2, 4],\n",
            "        [3, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBX0LgeO2eOA"
      },
      "source": [
        "# Generate distribution\n",
        "Here are some examples about generating numbers from different distributions. Cases of uniform, normal, bernoulli are given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV0CqXLf2dqs",
        "outputId": "bcb324c3-1e6f-4dc8-f9b7-e1d8c3eaf8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "u = torch.Tensor(2, 2).uniform_(0, 1)\n",
        "print(u)\n",
        "\n",
        "b = torch.bernoulli(u)  \n",
        "print(b)\n",
        "\n",
        "torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5309, 1.0000],\n",
            "        [0.3665, 0.3712]])\n",
            "tensor([[0., 1.],\n",
            "        [0., 1.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.1094,  0.4364,  2.9542,  3.8790,  5.0204,  6.2232,  6.9276,  7.7095,\n",
              "         8.5552, 10.1018])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGTj4ZehDlBS"
      },
      "source": [
        "# Running on a GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EGHfqZiDV19"
      },
      "source": [
        "import torch \n",
        "print(torch.__version__)\n",
        "\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.current_device())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcLFDsMCC-xj",
        "outputId": "a790b09b-8722-4e88-c5f9-65d91165df9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "a_cpu = torch.randn(100, 100, dtype=torch.float32)\n",
        "b_cpu = torch.randn(100, 100, dtype=torch.float32)\n",
        "\n",
        "a_gpu = a_cpu.cuda()\n",
        "b_gpu = b_cpu.cuda()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "t0 = time.time()\n",
        "c_cpu = a_cpu + b_cpu\n",
        "t1 = time.time()\n",
        "c_gpu = a_gpu + b_gpu\n",
        "torch.cuda.synchronize()\n",
        "t2 = time.time()\n",
        "\n",
        "# Check that they computed the same thing\n",
        "diff = (c_gpu.cpu() - c_cpu).abs().max().item()\n",
        "print('Max difference between c_gpu and c_cpu:', diff)\n",
        "\n",
        "cpu_time = 1000.0 * (t1 - t0)\n",
        "gpu_time = 1000.0 * (t2 - t1)\n",
        "print('CPU time: %.2f ms' % cpu_time)\n",
        "print('GPU time: %.2f ms' % gpu_time)\n",
        "print('GPU speedup: %.2f x' % (cpu_time / gpu_time))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0cf7854b3f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0ma_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mb_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n\u001b[1;32m    189\u001b[0m                 \"libcudart functions unavailable. It looks like you have a broken build?\")\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:47"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZsQHCOT_T4L"
      },
      "source": [
        ""
      ]
    }
  ]
}